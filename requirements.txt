¬°Por supuesto\! Aqu√≠ tienes el c√≥digo `app.py` actualizado con la ruta de tu archivo CSV ya corregida, junto con el archivo `requirements.txt` necesario para el despliegue en Streamlit Cloud.

Tu archivo CSV grande est√° ahora en GitHub, lo que significa que esta configuraci√≥n funcionar√° perfectamente.

-----

## üêç Archivo `app.py` (Finalizado)

Este script contiene toda la l√≥gica de ETL, ML (Isolation Forest, Score de Riesgo) y la interfaz de Streamlit.

```python
# ==============================================================================
# 1. IMPORTS Y CONFIGURACI√ìN INICIAL
# ==============================================================================
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.ensemble import IsolationForest
import warnings
import os

warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina (amplia para dashboards)
st.set_page_config(layout="wide")

# ==============================================================================
# 2. FUNCIONES DE PROCESAMIENTO Y CACHEO (ETL + M√âTRICAS + ML)
# ==============================================================================

# Funci√≥n para estandarizar nombres de columnas (de la Celda 3)
def clean_col_name(col):
    name = col.lower().strip()
    name = name.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u')
    name = name.replace(' ', '_').replace('.', '').replace('/', '_').replace(':', '').replace('(', '').replace(')', '')
    return name

# La funci√≥n principal de procesamiento que se cachea
@st.cache_data
def load_and_process_data(file_path):
    
    # ----------------------------------------
    # I. Carga y Limpieza (Celdas 2 y 3)
    # ----------------------------------------
    try:
        df = pd.read_csv(file_path, low_memory=False)
        df.columns = [clean_col_name(col) for col in df.columns]
    except Exception as e:
        st.error(f"Error al cargar o limpiar el CSV: {e}")
        return pd.DataFrame() 
    
    # ----------------------------------------
    # II. M√©trica de Completitud (Celda 5 original)
    # ----------------------------------------
    campos_minimos = [
        'titulo', 'descripcion', 'due√±o', 'correo_electronico_de_contacto', 
        'licencia', 'dominio', 'categoria', 'informacion_de_datos_frecuencia_de_actualizacion', 
        'common_core_public_access_level', 'informacion_de_datos_cobertura_geografica'
    ]
    campos_existentes = [col for col in campos_minimos if col in df.columns]
    num_campos_totales = len(campos_existentes)
    
    if num_campos_totales > 0:
        df['campos_diligenciados'] = df[campos_existentes].notna().sum(axis=1)
        df['completitud_score'] = (df['campos_diligenciados'] / num_campos_totales) * 100
    else:
        df['completitud_score'] = 0

    # ----------------------------------------
    # III. M√©tricas de Tiempo y Uso (Celda 6 original)
    # ----------------------------------------
    COLUMNA_FECHA_ACTUALIZACION = 'fecha_de_ultima_actualizacion_de_datos_utc' 
    COLUMNA_FRECUENCIA = 'informacion_de_datos_frecuencia_de_actualizacion'
    
    # Antig√ºedad
    df[COLUMNA_FECHA_ACTUALIZACION] = pd.to_datetime(df[COLUMNA_FECHA_ACTUALIZACION], errors='coerce', utc=True)
    HOY = pd.Timestamp.now(tz='utc') 
    df['antiguedad_datos_dias'] = (HOY - df[COLUMNA_FECHA_ACTUALIZACION]).dt.days.fillna(9999) 

    # Frecuencia y Cumplimiento
    mapa_frecuencia = {'diaria': 1, 'diario': 1, 'continuamente': 1, 'semanal': 7, 'quincenal': 15, 'mensual': 30, 'mensualmente': 30, 'bimestral': 60, 'trimestral': 90, 'semestral': 182, 'anual': 365, 'anualmente': 365, 'no aplica': 365 * 10, 'null': 365 * 10 }
    df['frecuencia_esperada_dias'] = df[COLUMNA_FRECUENCIA].astype(str).str.lower().str.strip().map(mapa_frecuencia).fillna(365 * 10) 
    UMBRAL_GRACIA_DIAS = 15 
    df['estado_actualizacion'] = np.where(
        df['antiguedad_datos_dias'] > (df['frecuencia_esperada_dias'] + UMBRAL_GRACIA_DIAS),
        'üî¥ INCUMPLIMIENTO',
        'üü¢ CUMPLE'
    )
    
    # Popularidad
    df['vistas'] = pd.to_numeric(df['vistas'], errors='coerce')
    df['descargas'] = pd.to_numeric(df['descargas'], errors='coerce')
    df['popularidad_score'] = (df['vistas'].fillna(0) * 0.6) + (df['descargas'].fillna(0) * 0.4)

    # ----------------------------------------
    # IV. Detecci√≥n de Anomal√≠as (Isolation Forest - Celda 4 modificada)
    # ----------------------------------------
    df['anomalia_score'] = 0 # Inicializar
    df_modelo = df[(df['antiguedad_datos_dias'] < 9999) & (df['popularidad_score'] > 0)].copy()
    
    if not df_modelo.empty:
        features = df_modelo[['antiguedad_datos_dias', 'popularidad_score', 'completitud_score']]
        model = IsolationForest(contamination=0.01, random_state=42)
        model.fit(features)
        anomalias = model.predict(features)
        df.loc[df_modelo.index, 'anomalia_score'] = anomalias

    # ----------------------------------------
    # V. Score de Prioridad/Riesgo (Celda 6 modificada)
    # ----------------------------------------
    df['riesgo_incumplimiento'] = np.where(df['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO', 3.0, 0.0)
    df['riesgo_completitud'] = np.where(df['completitud_score'] < 50, 1.5, 0.0)
    max_popularidad = df['popularidad_score'].max()
    df['riesgo_demanda'] = (df['popularidad_score'] / max_popularidad) * 1.0 if max_popularidad > 0 else 0.0
    df['riesgo_anomalia'] = np.where(df['anomalia_score'] == -1, 2.0, 0.0)
    
    df['prioridad_riesgo_score'] = (
        df['riesgo_incumplimiento'] + 
        df['riesgo_completitud'] + 
        df['riesgo_demanda'] +
        df['riesgo_anomalia']
    )
    
    # ----------------------------------------
    # VI. Filtrado P√∫blico (Celda 7)
    # ----------------------------------------
    df_publico = df[df['publico'].astype(str).str.lower().str.strip() == 'public'].copy()
    
    return df_publico

# ==============================================================================
# 3. EJECUCI√ìN DEL PROCESAMIENTO Y MANEJO DE ARCHIVOS
# ==============================================================================

# RUTA CORREGIDA: Usa el nombre del archivo subido con Git LFS
FILE_PATH = 'data/Asset_Inventory_-_Public_20251118.csv' 

try:
    df_publico = load_and_process_data(FILE_PATH)
except FileNotFoundError:
    st.error(f"Error: No se encontr√≥ el archivo '{FILE_PATH}'. Verifica la ruta en GitHub.")
    df_publico = pd.DataFrame()

if df_publico.empty:
    st.warning("No hay datos p√∫blicos para mostrar. Revisa la carga de datos o los filtros.")
    st.stop() 

# ==============================================================================
# 4. DISE√ëO DE LA INTERFAZ STREAMLIT
# ==============================================================================

st.title("üõ°Ô∏è Agente de Datos Abiertos: Diagn√≥stico de Calidad y Riesgo")
st.markdown("---")

# --- BARRA LATERAL Y FILTROS ---
st.sidebar.header("Filtros de An√°lisis")
entidad_seleccionada = st.sidebar.selectbox(
    "Filtrar Entidad Due√±a:", 
    options=['Todas'] + df_publico['due√±o'].dropna().unique().tolist()
)

# Aplicar filtro a la vista principal
if entidad_seleccionada != 'Todas':
    df_filtrado = df_publico[df_publico['due√±o'] == entidad_seleccionada]
else:
    df_filtrado = df_publico.copy()

# --- PESTA√ëAS PRINCIPALES ---
tab1, tab2, tab3 = st.tabs(["üö® Prioridad de Intervenci√≥n (OE2)", "üîç Diagn√≥stico (OE1)", "üí° Agente de Datos (LLM)"])

# ------------------------------------------------------------------------------
# PESTA√ëA 1: PRIORIDAD DE INTERVENCI√ìN (OE2/ML)
# ------------------------------------------------------------------------------
with tab1:
    st.header("1. Score de Riesgo y Prioridad de Intervenci√≥n")
    
    # KPIs R√°pidos
    col_kpi1, col_kpi2, col_kpi3, col_kpi4 = st.columns(4)
    
    num_incumplimiento = (df_filtrado['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO').sum()
    pct_incumplimiento = num_incumplimiento / len(df_filtrado) * 100 if len(df_filtrado) > 0 else 0
    
    num_anomalias = (df_filtrado['anomalia_score'] == -1).sum()
    avg_completitud = df_filtrado['completitud_score'].mean()
    avg_riesgo = df_filtrado['prioridad_riesgo_score'].mean()
    
    col_kpi1.metric("Activos en Incumplimiento", f"{num_incumplimiento} ({pct_incumplimiento:.1f}%)")
    col_kpi2.metric("Anomal√≠as ML Detectadas", num_anomalias)
    col_kpi3.metric("Completitud Promedio", f"{avg_completitud:.1f}%")
    col_kpi4.metric("Riesgo Promedio (Score)", f"{avg_riesgo:.2f}")

    st.markdown("---")
    
    # Gr√°fico de Prioridad (Celda 8)
    st.subheader("Visualizaci√≥n de Riesgo: Antig√ºedad vs. Score de Prioridad")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.scatterplot(
        x='antiguedad_datos_dias', 
        y='prioridad_riesgo_score', 
        data=df_filtrado, 
        hue='estado_actualizacion', 
        palette={'üî¥ INCUMPLIMIENTO': 'red', 'üü¢ CUMPLE': 'green'}, 
        size='popularidad_score',
        sizes=(50, 800),
        alpha=0.7,
        ax=ax
    )
    ax.set_title('Antig√ºedad vs. Score de Prioridad de Intervenci√≥n')
    ax.set_xlabel('Antig√ºedad de Datos (D√≠as)')
    ax.set_ylabel('Score de Prioridad de Riesgo')
    ax.axhline(y=df_filtrado['prioridad_riesgo_score'].quantile(0.75), color='red', linestyle='--', label='Prioridad Alta (Q3)')
    st.pyplot(fig)
    
    # Tabla de Top 20 Riesgosos
    st.subheader("Top 20 Activos de Mayor Riesgo (Prioridad de Intervenci√≥n)")
    top_riesgo = df_filtrado.sort_values('prioridad_riesgo_score', ascending=False).head(20)
    st.dataframe(top_riesgo[[
        'titulo', 'due√±o', 'antiguedad_datos_dias', 'completitud_score', 
        'popularidad_score', 'prioridad_riesgo_score', 'anomalia_score'
    ]].style.background_gradient(cmap='Reds', subset=['prioridad_riesgo_score']))


# ------------------------------------------------------------------------------
# PESTA√ëA 2: DIAGN√ìSTICO DE COHERENCIA Y COBERTURA (OE1)
# ------------------------------------------------------------------------------
with tab2:
    st.header("2. Diagn√≥stico de Coherencia y Cobertura")
    
    col_viz2_1, col_viz2_2 = st.columns(2)
    
    # Incumplimiento por Entidad (Celda 9)
    with col_viz2_1:
        st.subheader("Incumplimiento por Entidad")
        resumen_entidad = df_publico.groupby('due√±o').agg(
            Total_Activos=('titulo', 'count'),
            Activos_Incumplimiento=('estado_actualizacion', lambda x: (x == 'üî¥ INCUMPLIMIENTO').sum())
        ).reset_index()

        resumen_entidad['Porcentaje_Incumplimiento'] = (resumen_entidad['Activos_Incumplimiento'] / resumen_entidad['Total_Activos']) * 100
        resumen_entidad_top = resumen_entidad[resumen_entidad['Total_Activos'] >= 5].sort_values('Porcentaje_Incumplimiento', ascending=False).head(10)
        
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.barplot(x='Porcentaje_Incumplimiento', y='due√±o', data=resumen_entidad_top, palette='Reds_d', ax=ax2)
        ax2.set_xlabel('Porcentaje de Activos en INCUMPLIMIENTO (%)')
        ax2.set_ylabel('Entidad Responsable')
        st.pyplot(fig2)

    # Cobertura Tem√°tica (Celda 10 original - por Categor√≠a)
    with col_viz2_2:
        st.subheader("Cobertura Tem√°tica (por Categor√≠a)")
        conteo_categoria = df_publico['categoria'].value_counts().head(10)
        
        fig3, ax3 = plt.subplots(figsize=(8, 6))
        sns.barplot(x=conteo_categoria.values, y=conteo_categoria.index, palette='viridis', ax=ax3)
        ax3.set_xlabel('N√∫mero de Activos')
        ax3.set_ylabel('Categor√≠a')
        st.pyplot(fig3)

# ------------------------------------------------------------------------------
# PESTA√ëA 3: ASISTENTE LLM (SIMULACI√ìN)
# ------------------------------------------------------------------------------
with tab3:
    st.header("3. Asistente Inteligente Agente de Datos")
    st.markdown("""
        Esta secci√≥n simula el **Agente de Datos** basado en LLM.
        El Score de Riesgo (OE2), las Anomal√≠as (OE1) y las m√©tricas de Completitud 
        son la base de datos que usa este agente para generar respuestas y recomendaciones.
    """)
    
    st.subheader("Simulador de Recomendaciones Clave")
    
    # KPIs para el LLM
    peor_activo = df_filtrado.sort_values('prioridad_riesgo_score', ascending=False).iloc[0]
    peor_entidad = resumen_entidad_top.iloc[0] if not resumen_entidad_top.empty else None

    # Simular la respuesta del LLM
    respuesta_llm = f"""
    Basado en el an√°lisis de Machine Learning y las m√©tricas de completitud y actualizaci√≥n, estos son los hallazgos clave para **{entidad_seleccionada}**:
    
    **üî¥ Alerta de Alto Riesgo:**
    - El activo de m√°s alta prioridad para intervenci√≥n es: **'{peor_activo['titulo']}'**.
    - Su Score de Riesgo es de **{peor_activo['prioridad_riesgo_score']:.2f}** (m√°x. 7.5).
    - **Motivo de Riesgo:** El activo est√° en **{peor_activo['estado_actualizacion']}** y tiene una Completitud de solo **{peor_activo['completitud_score']:.1f}%**.
    
    **üì¢ Recomendaci√≥n de Gobernanza:**
    """
    if peor_entidad is not None and entidad_seleccionada == 'Todas':
        respuesta_llm += f"""
        - La entidad con el mayor desaf√≠o en cumplimiento de actualizaci√≥n es **{peor_entidad['due√±o']}**, con un **{peor_entidad['Porcentaje_Incumplimiento']:.1f}%** de sus activos en incumplimiento. Se recomienda iniciar un plan de seguimiento con este equipo.
        """
    else:
         respuesta_llm += f"""
        - Su entidad tiene un Score de Completitud promedio de **{avg_completitud:.1f}%**. Enfoque los esfuerzos de diligenciamiento de metadatos en aquellos activos con menos del 50% de completitud.
        """
        
    st.info(respuesta_llm)
    
    # Campo de Chat
    st.subheader("Consulta Interactiva")
    pregunta_usuario = st.text_input("Pregunta al Agente (e.g., ¬øCu√°l es la entidad que mejor cumple?):", "Mu√©strame los 5 activos m√°s usados que no cumplen con la frecuencia.")
    st.button("Consultar Agente")
    
    if pregunta_usuario:
        st.success(f"Analizando tu consulta: '{pregunta_usuario}'... (En el proyecto final, el LLM responder√≠a aqu√≠ usando las m√©tricas).")
```

-----

## üìÑ Archivo `requirements.txt`

Crea un archivo llamado `requirements.txt` en la ra√≠z de tu repositorio (al lado de `app.py`) con este contenido:

```
streamlit
pandas
numpy
matplotlib
seaborn
scikit-learn
```