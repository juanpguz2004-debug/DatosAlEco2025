import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import PercentFormatter
import io 
from datetime import datetime
import re 
import warnings
warnings.filterwarnings('ignore') # Ocultar advertencias de Pandas/Streamlit

# --- Variables Globales ---
ARCHIVO_PROCESADO = "Asset_Inventory_PROCESSED.csv" 
# CRITERIO DE RIESGO
UMBRAL_RIESGO_ALTO = 3.0 

# --- CONFIGURACI√ìN DE RIESGOS UNIVERSALES ---
PENALIZACION_DATOS_INCOMPLETOS = 2.0  
PENALIZACION_INCONSISTENCIA_TIPO = 0.5   
PENALIZACION_DUPLICADO = 1.0             
# RIESGO M√ÅXIMO TE√ìRICO: 2.0 + 0.5 + 1.0 = 3.5
RIESGO_MAXIMO_TEORICO_UNIVERSAL = 3.5 

# =================================================================
# 1. Funciones de Carga y Procesamiento
# =================================================================

@st.cache_data
def load_processed_data(file_path):
    """Carga el archivo CSV YA PROCESADO y lo cachea."""
    try:
        df = pd.read_csv(file_path, low_memory=False)
        return df
    except FileNotFoundError:
        return pd.DataFrame()

def clean_and_convert_types_external(df):
    """Fuerza a las columnas a ser tipo string para asegurar la detecci√≥n de inconsistencias."""
    
    # Columnas que suelen ser de tipo 'object' (string)
    object_cols = ['titulo', 'descripcion', 'due√±o'] 
    
    # Columnas que contienen los datos que queremos chequear por tipo mixto
    data_cols = [col for col in df.columns if col not in object_cols]
    
    for col in data_cols:
        if df[col].dtype != 'object':
            try:
                df[col] = df[col].astype(object) 
            except:
                pass 

    return df

def check_universals_external(df):
    """
    Calcula m√©tricas de calidad universal: Completitud (Datos), Consistencia, Unicidad 
    para el diagn√≥stico r√°pido.
    """
    n_cols = df.shape[1]
    
    # --- 1. COMPLETITUD: Datos por Fila (Densidad) ---
    df['datos_por_fila_score'] = (df.notna().sum(axis=1) / n_cols) * 100
    df['riesgo_datos_incompletos'] = np.where(
        df['datos_por_fila_score'] < 70, PENALIZACION_DATOS_INCOMPLETOS, 0.0
    )

    # --- 2. CONSISTENCIA: Mezcla de Tipos ---
    df['riesgo_consistencia_tipo'] = 0.0
    for col in df.select_dtypes(include='object').columns:
        inconsistencies = df[col].apply(lambda x: not isinstance(x, str) and pd.notna(x))
        df.loc[inconsistencies, 'riesgo_consistencia_tipo'] = PENALIZACION_INCONSISTENCIA_TIPO
        
    # --- 3. UNICIDAD: Duplicados Exactos ---
    df['es_duplicado'] = df.duplicated(keep=False) 
    df['riesgo_duplicado'] = np.where(
        df['es_duplicado'], PENALIZACION_DUPLICADO, 0.0
    )
    
    return df

def process_external_data(df):
    """
    L√≥gica de riesgo universal para el archivo externo subido (AJUSTADA).
    """
    
    # PASO CLAVE CORREGIDO: Asegurar que los tipos permitan la detecci√≥n
    df = clean_and_convert_types_external(df)

    # --- 1. EVALUACI√ìN DE UNIVERSALES (Completitud, Consistencia, Unicidad) ---
    df = check_universals_external(df)
    
    # --- 2. EVALUACI√ìN DE METADATOS A NIVEL DE ARCHIVO (SOLO PARA M√âTRICA) ---
    campos_clave_universal = ['titulo', 'descripcion', 'due√±o'] 
    campos_existentes_y_llenos = 0
    num_campos_totales_base = len(campos_clave_universal)

    for campo in campos_clave_universal:
        if campo in df.columns and pd.notna(df[campo].iloc[0]):
            campos_existentes_y_llenos += 1
            
    completitud_metadatos_universal = (campos_existentes_y_llenos / num_campos_totales_base) * 100
    df['completitud_metadatos_universal'] = completitud_metadatos_universal
    
    # --- 3. C√ÅLCULO FINAL DE RIESGO Y CALIDAD ---
    
    # Score de riesgo universal (SOLO 3 DIMENSIONES)
    df['prioridad_riesgo_score'] = (
        df['riesgo_datos_incompletos'] + 
        df['riesgo_consistencia_tipo'] +
        df['riesgo_duplicado']
    )
    
    # C√ÅLCULO DE CALIDAD TOTAL DEL ARCHIVO (0% a 100%)
    avg_file_risk = df['prioridad_riesgo_score'].mean()
    quality_score = 100 - (avg_file_risk / RIESGO_MAXIMO_TEORICO_UNIVERSAL * 100)
    
    df['calidad_total_score'] = np.clip(quality_score, 0, 100)

    return df

# --- FUNCI√ìN DE RECOMENDACI√ìN DETALLADA (CORREGIDA PARA MEJOR FORMATO) ---
def generate_specific_recommendation(risk_dimension):
    """Genera pasos de acci√≥n espec√≠ficos para la dimensi√≥n de riesgo m√°s alta."""
    
    # 1. Datos Incompletos (Completitud)
    if 'Datos Incompletos' in risk_dimension:
        return """
**Identificaci√≥n:** Localiza las columnas o filas con un alto porcentaje de valores **Nulos (NaN)**. El umbral de alerta se activa si el promedio de datos por fila es **menor al 70%**.

**Acci√≥n:** Revisa los procesos de ingesta de datos. Si el campo es **obligatorio**, aseg√∫rate de que todos los registros lo contengan. Si el campo es **opcional**, considera si es crucial para el an√°lisis antes de llenarlo con un valor por defecto.
        """
    # 2. Duplicados Exactos (Unicidad)
    elif 'Duplicados Exactos' in risk_dimension:
        return """
**Identificaci√≥n:** Encuentra las filas que son **copias exactas** (duplicados de todo el registro).

**Acci√≥n:** Revisa tu proceso de extracci√≥n/carga. Un duplicado exacto generalmente indica un error de procesamiento o ingesta. **Elimina las copias** y aseg√∫rate de que exista una **clave √∫nica** (UID) para cada registro que evite la re-ingesta accidental.
        """
    # 3. Consistencia de Tipo (Coherencia)
    elif 'Consistencia de Tipo' in risk_dimension:
        return """
**Identificaci√≥n:** Una columna contiene **datos mezclados** (ej. n√∫meros, fechas, y texto en una columna que deber√≠a ser solo n√∫meros). Esto afecta seriamente el an√°lisis.

**Acci√≥n:** Normaliza el tipo de dato para la columna afectada. Si es una columna num√©rica, **elimina los valores de texto** o convi√©rtelos a `NaN` para una limpieza posterior. Define el **tipo de dato esperado** (Schema) para cada columna y aplica una validaci√≥n estricta al inicio del proceso.
        """
    else:
        return "No se requiere una acci√≥n espec√≠fica o el riesgo detectado es demasiado bajo."


# =================================================================
# 2. Ejecuci√≥n Principal del Dashboard
# =================================================================

st.title("üìä Dashboard de Priorizaci√≥n de Activos de Datos (An√°lisis Completo)")

try:
    with st.spinner(f'Cargando archivo procesado: **{ARCHIVO_PROCESADO}**...'):
        df_analisis_completo = load_processed_data(ARCHIVO_PROCESADO) 

    if df_analisis_completo.empty:
        st.error(f"üõë Error: No se pudo cargar el archivo **{ARCHIVO_PROCESADO}**. Aseg√∫rate de que existe y se ejecut√≥ `preprocess.py`.")
    else:
        st.success(f'‚úÖ Archivo pre-procesado cargado. Total de activos: **{len(df_analisis_completo)}**')

        # --- SECCI√ìN DE SELECCI√ìN Y DESGLOSE DE ENTIDAD ---
        owners = df_analisis_completo['due√±o'].dropna().unique().tolist()
        owners.sort()
        owners.insert(0, "Mostrar An√°lisis General")
        
        filtro_due√±o = st.selectbox(
            "Selecciona una Entidad para ver su Desglose de Estad√≠sticas:",
            owners
        )
        
        # --- DESGLOSE DE ESTAD√çSTICAS (KPIs) ---
        if filtro_due√±o != "Mostrar An√°lisis General":
            df_entidad_seleccionada = df_analisis_completo[df_analisis_completo['due√±o'] == filtro_due√±o]
            
            if not df_entidad_seleccionada.empty:
                st.subheader(f"Estad√≠sticas Clave para: **{filtro_due√±o}**")
                
                total_activos = len(df_entidad_seleccionada)
                incumplimiento = (df_entidad_seleccionada['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO').sum()
                
                col1, col2, col3, col4, col5 = st.columns(5)
                
                col1.metric("Activos Totales", total_activos)
                col2.metric("Completitud Promedio", f"{df_entidad_seleccionada['completitud_score'].mean():.2f}%")
                col3.metric("Riesgo Promedio", f"{df_entidad_seleccionada['prioridad_riesgo_score'].mean():.2f}")
                col4.metric("Incumplimiento Absoluto", f"{incumplimiento} / {total_activos}")
                
                if 'antiguedad_datos_dias' in df_entidad_seleccionada.columns:
                    col5.metric("Antig√ºedad Promedio", f"{df_entidad_seleccionada['antiguedad_datos_dias'].mean():.0f} d√≠as")
                else:
                    col5.metric("Antig√ºedad Promedio", "N/A")
                
                st.markdown("---")
            else:
                st.warning(f"‚ö†Ô∏è No se encontraron activos para la entidad: {filtro_due√±o}")
                st.markdown("---")

        # --- BARRA LATERAL (FILTROS SECUNDARIOS) ---
        st.sidebar.header("‚öôÔ∏è Filtros para Visualizaciones")
        
        filtro_acceso = "Mostrar Todos"
        if 'common_core_public_access_level' in df_analisis_completo.columns:
            access_levels = df_analisis_completo['common_core_public_access_level'].dropna().unique().tolist()
            access_levels.sort()
            access_levels.insert(0, "Mostrar Todos")
            filtro_acceso = st.sidebar.selectbox("Filtrar por Nivel de Acceso:", access_levels)

        filtro_categoria = "Mostrar Todos"
        if 'categoria' in df_analisis_completo.columns:
            categories = df_analisis_completo['categoria'].dropna().unique().tolist()
            categories.sort()
            categories.insert(0, "Mostrar Todos")
            filtro_categoria = st.sidebar.selectbox("Filtrar por Categor√≠a:", categories)


        # --- APLICAR FILTROS (Para las Visualizaciones) ---
        df_filtrado = df_analisis_completo.copy()
        
        if filtro_due√±o != "Mostrar An√°lisis General":
             df_filtrado = df_filtrado[df_filtrado['due√±o'] == filtro_due√±o]

        if filtro_acceso != "Mostrar Todos":
             df_filtrado = df_filtrado[df_filtrado['common_core_public_access_level'] == filtro_acceso]

        if filtro_categoria != "Mostrar Todos":
            df_filtrado = df_filtrado[df_filtrado['categoria'] == filtro_categoria]

        st.header("üìä Visualizaciones y Rankings")
        st.info(f"Vista actual de gr√°ficos: **{len(df_filtrado)} activos** (Filtro de Entidad: {filtro_due√±o}; Acceso: {filtro_acceso}; Categor√≠a: {filtro_categoria})")

        if df_filtrado.empty:
            st.warning("‚ö†Ô∏è No hay datos para mostrar en los gr√°ficos con los filtros seleccionados.")
        else:
            
            # --- 3. M√©tricas de la Vista Actual ---
            st.subheader("M√©tricas de la Vista Actual")
            col_metrica1, col_metrica2, col_metrica3 = st.columns(3)
            col_metrica1.metric("Completitud Promedio", f"{df_filtrado['completitud_score'].mean():.2f}%")
            col_metrica2.metric("Activos en Incumplimiento", f"{(df_filtrado['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO').sum()} / {len(df_filtrado)}")
            col_metrica3.metric("Anomal√≠as Detectadas (ML)", f"{(df_filtrado['anomalia_score'] == -1).sum()}")
            
            st.markdown("---")

            # --- 4. Tabla de B√∫squeda y Diagn√≥stico de Entidades (Con Color Condicional) ---
            st.header("üîç 4. Tabla de B√∫squeda y Diagn√≥stico de Entidades")

            # TEXTO CORREGIDO PARA EL NUEVO UMBRAL (3.0)
            st.info(f"""
                La columna **Riesgo Promedio** tiene un formato de color:
                * üü¢ **Verde:** El riesgo promedio es **menor o igual a {UMBRAL_RIESGO_ALTO:.1f}**. Intervenci√≥n no urgente.
                * üî¥ **Rojo:** El riesgo promedio es **mayor a {UMBRAL_RIESGO_ALTO:.1f}**. Se requiere **intervenci√≥n/actualizaci√≥n prioritaria**.
            """)
            
            resumen_entidades_busqueda = df_filtrado.groupby('due√±o').agg(
                Activos_Totales=('uid', 'count'),
                Riesgo_Promedio=('prioridad_riesgo_score', 'mean'),
                Completitud_Promedio=('completitud_score', 'mean'),
                Antiguedad_Promedio_Dias=('antiguedad_datos_dias', 'mean'),
                Incumplimiento_Absoluto=('estado_actualizacion', lambda x: (x == 'üî¥ INCUMPLIMIENTO').sum())
            ).reset_index()

            resumen_entidades_busqueda['%_Incumplimiento'] = (resumen_entidades_busqueda['Incumplimiento_Absoluto'] / resumen_entidades_busqueda['Activos_Totales']) * 100
            resumen_entidades_busqueda = resumen_entidades_busqueda.rename(columns={'due√±o': 'Entidad Responsable'})
            resumen_entidades_busqueda = resumen_entidades_busqueda.sort_values(by='Riesgo_Promedio', ascending=False)
            
            def color_riesgo_promedio(val):
                color = 'background-color: #f79999' if val > UMBRAL_RIESGO_ALTO else 'background-color: #a9dfbf'
                return color
            
            styled_df = resumen_entidades_busqueda.style.applymap(
                color_riesgo_promedio, 
                subset=['Riesgo_Promedio']
            ).format({
                'Riesgo_Promedio': '{:.2f}',
                'Completitud_Promedio': '{:.2f}%',
                'Antiguedad_Promedio_Dias': '{:.0f}',
                '%_Incumplimiento': '{:.2f}%'
            })


            st.dataframe(
                styled_df, 
                use_container_width=True,
                column_config={
                    'Entidad Responsable': st.column_config.TextColumn("Entidad Responsable"),
                    'Activos_Totales': st.column_config.NumberColumn("Activos Totales"),
                    'Riesgo_Promedio': st.column_config.NumberColumn("Riesgo Promedio (Score)", help=f"Rojo > {UMBRAL_RIESGO_ALTO:.1f}."),
                    'Completitud_Promedio': st.column_config.NumberColumn("Completitud Promedio", format="%.2f%%"),
                    'Antiguedad_Promedio_Dias': st.column_config.NumberColumn("Antig√ºedad Promedio (D√≠as)", format="%d"),
                    'Incumplimiento_Absoluto': st.column_config.NumberColumn("Activos en Incumplimiento (Count)"),
                    '%_Incumplimiento': st.column_config.TextColumn("% Incumplimiento")
                },
                hide_index=True
            )

            st.markdown("---")
            
            # --- PESTA√ëAS PARA EL "CARRUSEL" DE VISUALIZACIONES ---
            tab1, tab2, tab3 = st.tabs(["1. Ranking de Completitud", "2. Burbujas de Riesgo", "3. Cobertura Tem√°tica"])

            with tab1:
                # --- Visualizaci√≥n 1: Ranking de Completitud (Peor Rendimiento) ---
                st.subheader("1. üìâ Ranking de Entidades por Completitud Promedio (Peor Rendimiento)")
                
                try:
                    COLUMNA_ENTIDAD = 'due√±o'
                    resumen_completitud = df_filtrado.groupby(COLUMNA_ENTIDAD).agg(
                        Total_Activos=('uid', 'count'),
                        Completitud_Promedio=('completitud_score', 'mean')
                    ).reset_index()
                    
                    entidades_volumen = resumen_completitud[resumen_completitud['Total_Activos'] >= 5]
                    df_top_10_peor_completitud = entidades_volumen.sort_values(by='Completitud_Promedio', ascending=True).head(10)
                    
                    if not df_top_10_peor_completitud.empty:
                        fig1, ax1 = plt.subplots(figsize=(10, 6))
                        sns.barplot(x='Completitud_Promedio', y=COLUMNA_ENTIDAD, data=df_top_10_peor_completitud, palette='Reds_r', ax=ax1)
                        ax1.set_title('Top 10 Entidades con Peor Completitud Promedio', fontsize=14)
                        ax1.set_xlabel('Score de Completitud Promedio (%)', fontsize=12)
                        ax1.set_ylabel('Entidad Responsable', fontsize=12)
                        st.pyplot(fig1)
                    else:
                        st.warning("No hay entidades con suficiente volumen (>= 5 activos) para generar el ranking.")
                except Exception as e:
                    st.error(f"‚ùå ERROR [Visualizaci√≥n 1]: Fall√≥ la generaci√≥n del Gr√°fico de Completitud. Detalle: {e}")

            with tab2:
                # --- Visualizaci√≥n 2: Gr√°fico de Burbujas de Riesgo ---
                st.subheader("2. ü´ß Burbujas de Priorizaci√≥n de Riesgo por Entidad")
                st.markdown("Este gr√°fico muestra la **relaci√≥n entre el riesgo, la completitud de metadatos y el volumen de activos** por entidad.")
                st.markdown("* **Eje X:** Riesgo Promedio (Se debe minimizar, mejor a la izquierda).")
                st.markdown("* **Eje Y:** Completitud Promedio (Se debe maximizar, mejor arriba).")
                st.markdown("* **Tama√±o de Burbuja:** Volumen de Activos.")

                try:
                    df_bubble = df_filtrado.groupby('due√±o').agg(
                        Riesgo_Promedio=('prioridad_riesgo_score', 'mean'),
                        Completitud_Promedio=('completitud_score', 'mean'),
                        Volumen=('uid', 'count')
                    ).reset_index()
                    
                    if not df_bubble.empty:
                        fig2, ax2 = plt.subplots(figsize=(12, 8))
                        
                        max_volumen = df_bubble['Volumen'].max()
                        s_volumen = (df_bubble['Volumen'] / max_volumen) * 2000 
                        
                        scatter = ax2.scatter(
                            x=df_bubble['Riesgo_Promedio'], 
                            y=df_bubble['Completitud_Promedio'], 
                            s=s_volumen, 
                            c=df_bubble['Completitud_Promedio'], 
                            cmap='RdYlGn', 
                            alpha=0.6, 
                            edgecolors="w", 
                            linewidth=1
                        )
                        
                        for i in df_bubble.nlargest(5, 'Volumen').index:
                             ax2.annotate(df_bubble.loc[i, 'due√±o'], 
                                         (df_bubble.loc[i, 'Riesgo_Promedio'], df_bubble.loc[i, 'Completitud_Promedio']), 
                                         fontsize=8, alpha=0.8)

                        ax2.axhline(80, color='gray', linestyle='--', alpha=0.5)
                        ax2.axvline(UMBRAL_RIESGO_ALTO, color='red', linestyle=':', alpha=0.7)

                        ax2.set_xlabel('Riesgo Promedio (Peor ‚Üí)', fontsize=12)
                        ax2.set_ylabel('Completitud Promedio (Mejor ‚Üë)', fontsize=12)
                        ax2.set_title('Matriz de Priorizaci√≥n de Entidades (Riesgo vs. Completitud)', fontsize=16)
                        
                        cbar = fig2.colorbar(scatter, ax=ax2)
                        cbar.set_label('Completitud Promedio (%)')
                        
                        st.pyplot(fig2)
                    else:
                        st.warning("No hay suficientes datos de entidad para generar el Gr√°fico de Burbujas.")
                        
                except Exception as e:
                    st.error(f"‚ùå ERROR [Visualizaci√≥n 2]: Fall√≥ la generaci√≥n del Gr√°fico de Burbujas. Detalle: {e}")


            with tab3:
                # --- Visualizaci√≥n 3: Cobertura Tem√°tica por Categor√≠a ---
                st.subheader("3. üó∫Ô∏è Cobertura Tem√°tica por Categor√≠a")
                
                try:
                    COLUMNA_CATEGORIA = 'categoria'
                    if COLUMNA_CATEGORIA in df_filtrado.columns:
                        conteo_categoria = df_filtrado[COLUMNA_CATEGORIA].value_counts().head(10)
                    else:
                        conteo_categoria = pd.Series([], dtype='int')

                    if not conteo_categoria.empty:
                        fig3, ax3 = plt.subplots(figsize=(10, 7))
                        sns.barplot(x=conteo_categoria.values, y=conteo_categoria.index, palette='viridis', ax=ax3)
                        ax3.set_title('Top 10 Categor√≠as con Mayor Cobertura Tem√°tica', fontsize=16)
                        ax3.set_xlabel('N√∫mero de Activos', fontsize=12)
                        ax3.set_ylabel('Categor√≠a', fontsize=12)
                        st.pyplot(fig3)
                    else:
                        st.warning("La columna 'categoria' no contiene suficientes valores para generar la visualizaci√≥n.")
                except Exception as e:
                    st.error(f"‚ùå ERROR [Visualizaci√≥n 3]: Fall√≥ la generaci√≥n del Bar Plot de Categor√≠as. Detalle: {e}")


        
        # ----------------------------------------------------------------------
        # --- SECCI√ìN 5: DIAGN√ìSTICO DE ARCHIVO EXTERNO
        # ----------------------------------------------------------------------
        st.markdown("<hr style='border: 4px solid #f0f2f6;'>", unsafe_allow_html=True)
        st.header("üíæ Diagn√≥stico de Archivo CSV Externo (Calidad Universal)")
        st.markdown(f"Sube un archivo CSV. La **Calidad Total** se calcula en base a 3 dimensiones universales (Riesgo M√°ximo: **{RIESGO_MAXIMO_TEORICO_UNIVERSAL:.1f}**).")

        uploaded_file = st.file_uploader(
            "Selecciona el Archivo CSV", 
            type="csv"
        )

        if uploaded_file is not None:
            with st.spinner('Analizando archivo...'):
                try:
                    uploaded_filename = uploaded_file.name
                    # L√≥gica de lectura robusta con detecci√≥n de delimitadores
                    uploaded_df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")), low_memory=False)
                    if len(uploaded_df.columns) <= 1:
                        uploaded_file.seek(0)
                        uploaded_df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")), low_memory=False, sep=';')
                        if len(uploaded_df.columns) <= 1:
                            uploaded_file.seek(0)
                            uploaded_df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")), low_memory=False, sep='\t')


                    if uploaded_df.empty:
                        st.warning(f"‚ö†Ô∏è El archivo subido **{uploaded_filename}** est√° vac√≠o.")
                    else:
                        df_diagnostico = process_external_data(uploaded_df.copy())
                        
                        if not df_diagnostico.empty:
                            
                            # M√©tricas consolidadas
                            calidad_total_final = df_diagnostico['calidad_total_score'].iloc[0] 
                            completitud_universal_promedio = df_diagnostico['completitud_metadatos_universal'].iloc[0] 
                            riesgo_promedio_total = df_diagnostico['prioridad_riesgo_score'].mean()

                            # Desglose de Riesgos Promedio (ELIMINANDO METADATOS)
                            riesgos_reporte = pd.DataFrame({
                                'Dimensi√≥n de Riesgo': [
                                    '1. Datos Incompletos (Completitud)',
                                    '2. Duplicados Exactos (Unicidad)',
                                    '3. Consistencia de Tipo (Coherencia)',
                                ],
                                'Riesgo Promedio (0-M√°x)': [
                                    df_diagnostico['riesgo_datos_incompletos'].mean(),
                                    df_diagnostico['riesgo_duplicado'].mean(),
                                    df_diagnostico['riesgo_consistencia_tipo'].mean(),
                                ]
                            })
                            riesgos_reporte = riesgos_reporte.sort_values(by='Riesgo Promedio (0-M√°x)', ascending=False)
                            riesgos_reporte['Riesgo Promedio (0-M√°x)'] = riesgos_reporte['Riesgo Promedio (0-M√°x)'].round(2)
                            
                            
                            # === L√ìGICA DE RECOMENDACI√ìN PR√ÅCTICA (CORREGIDA) ===
                            
                            recomendacion_final_md = ""
                            
                            riesgo_max_reportado = riesgos_reporte.iloc[0]['Riesgo Promedio (0-M√°x)']
                            
                            if riesgo_max_reportado > 0.15:
                                # Identificar el riesgo m√°s alto
                                riesgo_dimension_max = riesgos_reporte.iloc[0]['Dimensi√≥n de Riesgo']
                                
                                # Generar la explicaci√≥n espec√≠fica
                                explicacion_especifica = generate_specific_recommendation(riesgo_dimension_max)
                                
                                # Formato de salida con bloques de c√≥digo para claridad
                                recomendacion_final_md = f"""
El riesgo m√°s alto es por **{riesgo_dimension_max}** ({riesgo_max_reportado:.2f}). Enfoca tu esfuerzo en corregir este problema primero.

<br>

**Detalle y Acciones:**

{explicacion_especifica}
"""

                            if not recomendacion_final_md:
                                recomendacion_final_md = "La Calidad es excelente. No se requieren mejoras prioritarias en las dimensiones analizadas."
                                estado = "üü¢ CALIDAD ALTA"
                                color = "green"
                            else:
                                if calidad_total_final < 60:
                                    estado = "üî¥ CALIDAD BAJA (URGENTE)"
                                    color = "red"
                                elif calidad_total_final < 85:
                                    estado = "üü° CALIDAD MEDIA (MEJORA REQUERIDA)"
                                    color = "orange"
                                else:
                                    estado = "üü¢ CALIDAD ACEPTABLE"
                                    color = "green"

                            # === FIN L√ìGICA DE RECOMENDACI√ìN ===
                            
                            st.subheader("Resultados del Diagn√≥stico R√°pido")
                            
                            # --- DESPLIEGUE DE M√âTRICAS SIMPLIFICADO ---
                            col_calidad, col_meta, col_riesgo = st.columns(3)
                            
                            col_calidad.metric("‚≠ê Calidad Total del Archivo", f"{calidad_total_final:.1f}%")
                            col_meta.metric("Completitud Metadatos (Avg)", f"{completitud_universal_promedio:.2f}%") 
                            col_riesgo.metric("Riesgo Promedio Total", f"{riesgo_promedio_total:.2f}")

                            # Despliegue de la Recomendaci√≥n
                            st.markdown(f"""
                                <div style='border: 2px solid {color}; padding: 15px; border-radius: 5px; background-color: #f9f9f9;'>
                                    <h4 style='color: {color}; margin-top: 0;'>Diagn√≥stico General: {estado}</h4>
                                </div>
                            """, unsafe_allow_html=True)
                            
                            st.markdown("#### üî¨ Desglose de Riesgos (Auditor√≠a)")
                            
                            # CORRECCI√ìN DE VISUALIZACI√ìN DE TABLA DE RIESGOS
                            st.table(
                                riesgos_reporte.set_index('Dimensi√≥n de Riesgo') 
                            )

                            st.markdown(f"#### ‚ú® Recomendaci√≥n de Acciones:")
                            st.markdown(recomendacion_final_md, unsafe_allow_html=True)

                        else:
                            st.error(f"‚ùå El archivo subido **{uploaded_filename}** no pudo ser procesado.")
                            
                except Exception as e:
                    st.error(f"‚ùå Error al leer o procesar el archivo CSV: {e}")
                    
except Exception as e:
    st.error(f"‚ùå ERROR FATAL: Ocurri√≥ un error inesperado al iniciar la aplicaci√≥n: {e}")
