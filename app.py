import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from datetime import datetime, date 

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Dashboard de Diagn√≥stico de Activos",
    layout="wide"
)

# --- Nombre del archivo CSV que Streamlit debe encontrar ---
ARCHIVO_CSV = "Asset_Inventory_-_Public_20251118.csv"

## 1. Funciones de Procesamiento de Datos

def clean_col_name(col):
    name = col.lower().strip()
    name = name.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u')
    name = name.replace(' ', '_').replace('.', '').replace('/', '_').replace(':', '').replace('(', '').replace(')', '')
    return name

def calculate_antiguedad_y_estado(df_temp):
    try:
        COL_FECHA_ACTUALIZACION = 'fecha_de_ultima_actualizacion_de_datos_utc'
        COL_FRECUENCIA = 'informacion_de_datos_frecuencia_de_actualizacion'

        df_temp[COL_FECHA_ACTUALIZACION] = pd.to_datetime(df_temp[COL_FECHA_ACTUALIZACION], errors='coerce', utc=True)
        
        hoy = pd.to_datetime(datetime.now().date(), utc=True)
        df_temp['antiguedad_datos_dias'] = (hoy - df_temp[COL_FECHA_ACTUALIZACION]).dt.days
        
        mapa_frecuencia = {
            'diario': 1, 'semanal': 7, 'quincenal': 15, 'mensual': 30, 
            'trimestral': 90, 'semestral': 180, 'anual': 365
        }
        df_temp['frecuencia_esperada_dias'] = df_temp[COL_FRECUENCIA].astype(str).str.lower().str.strip().map(mapa_frecuencia).fillna(9999)

        df_temp['estado_actualizacion'] = np.where(
            (df_temp['antiguedad_datos_dias'] > df_temp['frecuencia_esperada_dias']) & 
            (df_temp['frecuencia_esperada_dias'] < 9999), 
            'üî¥ INCUMPLIMIENTO', 
            'üü¢ CUMPLE'
        )
        return df_temp
    except KeyError as e:
        st.error(f"‚ùå ERROR [Paso Antig√ºedad]: No se encontr√≥ la columna de fecha o frecuencia requerida: {e}. Revisa el nombre.")
        raise
    except Exception as e:
        st.error(f"‚ùå ERROR INESPERADO [Paso Antig√ºedad]: Fall√≥ el c√°lculo de antig√ºedad: {e}.")
        raise


@st.cache_data
def process_data(df):
    
    # 1. Limpieza de nombres de columnas
    df.columns = [clean_col_name(col) for col in df.columns]

    # --- CORRECCI√ìN y VERIFICACI√ìN DE POPULARIDAD ---
    try:
        df['vistas'] = pd.to_numeric(df.get('vistas'), errors='coerce')
        df['descargas'] = pd.to_numeric(df.get('descargas'), errors='coerce')
        df['popularidad_score'] = df['vistas'].fillna(0) + df['descargas'].fillna(0) 
    except Exception as e:
        st.error(f"‚ùå ERROR [Paso Popularidad]: Fall√≥ la conversi√≥n o suma de 'vistas'/'descargas'. Detalle: {e}")
        return pd.DataFrame() 

    # 2. C√ÅLCULOS PREVIOS (Antig√ºedad y Estado de Actualizaci√≥n)
    try:
        df = calculate_antiguedad_y_estado(df.copy()) 
    except Exception as e:
        return pd.DataFrame() 
    
    # 3. C√ÅLCULO DE M√âTRICA DE COMPLETITUD
    try:
        campos_minimos = [
            'titulo', 'descripcion', 'due√±o', 'correo_electronico_de_contacto',
            'licencia', 'dominio', 'categoria', 'informacion_de_datos_frecuencia_de_actualizacion',
            'common_core_public_access_level', 'informacion_de_datos_cobertura_geografica'
        ]
        campos_existentes = [col for col in campos_minimos if col in df.columns]
        num_campos_totales = len(campos_existentes)
        df['campos_diligenciados'] = df[campos_existentes].notna().sum(axis=1)
        df['completitud_score'] = (df['campos_diligenciados'] / num_campos_totales) * 100
    except Exception as e:
        st.error(f"‚ùå ERROR [Paso Completitud]: Fall√≥ el c√°lculo de 'completitud_score'. Detalle: {e}")
        return pd.DataFrame()
    
    # 4. DETECCI√ìN DE ANOMAL√çAS (Isolation Forest)
    try:
        df['anomalia_score'] = 0 
        df_modelo = df[(df['antiguedad_datos_dias'] < 9999) & (df['popularidad_score'] > 0)].copy()
        
        if not df_modelo.empty and len(df_modelo) > 1: 
            features = df_modelo[['antiguedad_datos_dias', 'popularidad_score', 'completitud_score']]
            model = IsolationForest(contamination=0.01, random_state=42)
            model.fit(features)
            anomalias = model.predict(features)
            df.loc[df_modelo.index, 'anomalia_score'] = anomalias
    except ImportError:
        st.error("‚ùå ERROR [Paso Anomal√≠as]: `scikit-learn` no est√° instalado. Instala: `pip install scikit-learn`.")
    except Exception as e:
        st.error(f"‚ùå ERROR [Paso Anomal√≠as]: Fall√≥ el modelo Isolation Forest. Detalle: {e}")

    # 5. C√ÅLCULO DE SCORE DE RIESGO/PRIORIDAD
    try:
        max_popularidad = df['popularidad_score'].max()
        max_popularidad = max_popularidad if max_popularidad > 0 else 1 

        df['riesgo_incumplimiento'] = np.where(df['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO', 3.0, 0.0)
        df['riesgo_completitud'] = np.where(df['completitud_score'] < 50, 1.5, 0.0)
        df['riesgo_demanda'] = (df['popularidad_score'] / max_popularidad) * 1.0
        df['riesgo_anomalia'] = np.where(df['anomalia_score'] == -1, 2.0, 0.0)
        
        df['prioridad_riesgo_score'] = (
            df['riesgo_incumplimiento'] +
            df['riesgo_completitud'] +
            df['riesgo_demanda'] +
            df['riesgo_anomalia']
        )
    except Exception as e:
        st.error(f"‚ùå ERROR [Paso Score Riesgo]: Fall√≥ el c√°lculo del score final. Detalle: {e}")
        return pd.DataFrame() 
    
    return df

## 2. T√≠tulo y Ejecuci√≥n Principal

st.title("üìä Dashboard de Priorizaci√≥n de Activos de Datos (Todos los Activos)")

try:
    with st.spinner(f'Cargando y procesando el archivo: **{ARCHIVO_CSV}**...'):
        df = pd.read_csv(ARCHIVO_CSV, low_memory=False)
        df_analisis_completo = process_data(df.copy()) 
        
    if df_analisis_completo.empty:
        st.error("üõë Proceso de datos detenido debido a errores previos. Revisa los mensajes de error ‚ùå para depurar.")
    else:
        st.success(f'‚úÖ Archivo **{ARCHIVO_CSV}** cargado y procesamiento completado. Total de activos: **{len(df_analisis_completo)}**')
        
        # --- 2.1 BARRA LATERAL (FILTROS) ---
        st.sidebar.header("‚öôÔ∏è Filtros de An√°lisis")
        
        # Opci√≥n para filtrar por DUE√ëO (Entidad)
        owners = df_analisis_completo['due√±o'].dropna().unique().tolist()
        owners.sort()
        owners.insert(0, "Mostrar Todos los Activos")
        
        filtro_due√±o = st.sidebar.selectbox(
            "Filtrar por Entidad Responsable:",
            owners
        )
        
        # Opci√≥n para filtrar por CATEGOR√çA
        categories = df_analisis_completo['categoria'].dropna().unique().tolist()
        categories.sort()
        categories.insert(0, "Mostrar Todos")
        
        filtro_categoria = st.sidebar.selectbox(
            "Filtrar por Categor√≠a:",
            categories
        )

        # --- 2.2 APLICAR FILTROS ---
        df_filtrado = df_analisis_completo.copy()
        
        if filtro_due√±o != "Mostrar Todos los Activos":
            df_filtrado = df_filtrado[df_filtrado['due√±o'] == filtro_due√±o]
            st.info(f"Filtro aplicado: **Entidad = {filtro_due√±o}**")

        if filtro_categoria != "Mostrar Todos":
            df_filtrado = df_filtrado[df_filtrado['categoria'] == filtro_categoria]
            st.info(f"Filtro aplicado: **Categor√≠a = {filtro_categoria}**")

        st.markdown(f"---")
        st.write(f"Activos en la vista actual: **{len(df_filtrado)}**")

        if df_filtrado.empty:
            st.warning("‚ö†Ô∏è No hay datos para mostrar con los filtros seleccionados.")
        else:
            
            # --- 3. M√©tricas y Visualizaciones ---
            
            st.header("üîç Resultados Clave de Calidad y Prioridad")
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Completitud Promedio", f"{df_filtrado['completitud_score'].mean():.2f}%")
            col2.metric("Activos en Incumplimiento", f"{(df_filtrado['estado_actualizacion'] == 'üî¥ INCUMPLIMIENTO').sum()} / {len(df_filtrado)}")
            col3.metric("Anomal√≠as Detectadas (ML)", f"{(df_filtrado['anomalia_score'] == -1).sum()}")
            
            
            # --- Visualizaci√≥n 1: Gr√°fico de Barras de Completitud por Entidad ---
            st.subheader("1. üìâ Completitud Promedio por Entidad (Top 10 Peor Rendimiento)")
            st.markdown("Este gr√°fico muestra las **10 entidades** (`due√±o`) en la vista actual con el **Score de Completitud Promedio m√°s bajo**. Estos sectores requieren la mayor atenci√≥n para mejorar la documentaci√≥n de sus activos.")
            
            try:
                COLUMNA_ENTIDAD = 'due√±o'
                
                # Agrupar por Entidad y calcular el Score de Completitud Promedio
                resumen_completitud = df_filtrado.groupby(COLUMNA_ENTIDAD).agg(
                    Total_Activos=('uid', 'count'),
                    Completitud_Promedio=('completitud_score', 'mean')
                ).reset_index()
                
                # Filtrar entidades con volumen m√≠nimo (ejemplo: 5 activos)
                entidades_volumen = resumen_completitud[resumen_completitud['Total_Activos'] >= 5]
                
                # Ordenar para obtener el TOP 10 con la PEOR COMPLETITUD (el promedio m√°s bajo)
                df_top_10_peor_completitud = entidades_volumen.sort_values(
                    by='Completitud_Promedio', 
                    ascending=True # Orden ascendente para mostrar lo peor primero
                ).head(10)
                
                if not df_top_10_peor_completitud.empty:
                    fig1, ax1 = plt.subplots(figsize=(10, 6))
                    sns.barplot(
                        x='Completitud_Promedio',
                        y=COLUMNA_ENTIDAD,
                        data=df_top_10_peor_completitud,
                        palette='Reds_r', # Paleta que destaca los valores bajos
                        ax=ax1
                    )
                    
                    ax1.set_title('Top 10 Entidades con Peor Completitud Promedio (M√≠n. 5 activos)', fontsize=14)
                    ax1.set_xlabel('Score de Completitud Promedio (%)', fontsize=12)
                    ax1.set_ylabel('Entidad Responsable', fontsize=12)
                    ax1.grid(axis='x', linestyle='--', alpha=0.6)
                    plt.tight_layout()
                    st.pyplot(fig1)

                    st.markdown("### Resumen de Completitud (Top 10 Peor)")
                    st.dataframe(df_top_10_peor_completitud.sort_values(by='Completitud_Promedio', ascending=True), use_container_width=True)
                else:
                    st.info("No hay entidades con suficiente volumen (>= 5 activos) para generar el ranking de Completitud en la vista actual.")

            except Exception as e:
                st.error(f"‚ùå ERROR [Visualizaci√≥n 1]: Fall√≥ la generaci√≥n del Gr√°fico de Completitud. Detalle: {e}")

            st.markdown("---")


            # --- Visualizaci√≥n 2: Top 10 Entidades con Incumplimiento ---
            st.subheader("2. Top 10 Entidades con Mayor Porcentaje de Incumplimiento (Vista Total)")
            
            # Esta visualizaci√≥n usa el an√°lisis COMPLETO (df_analisis_completo) para mostrar el ranking general.
            df_para_ranking = df_analisis_completo.copy() 

            try:
                COLUMNA_ENTIDAD = 'due√±o'
                # Asegurar que la entidad tenga al menos 5 activos para ser relevante
                entidades_con_volumen = df_para_ranking.groupby(COLUMNA_ENTIDAD).filter(lambda x: len(x) >= 5)

                if not entidades_con_volumen.empty:
                    resumen_entidad = entidades_con_volumen.groupby(COLUMNA_ENTIDAD).agg(
                        Total_Activos=('uid', 'count'),
                        Activos_Incumplimiento=('estado_actualizacion', lambda x: (x == 'üî¥ INCUMPLIMIENTO').sum())
                    ).reset_index()

                    resumen_entidad['Porcentaje_Incumplimiento'] = (resumen_entidad['Activos_Incumplimiento'] / resumen_entidad['Total_Activos']) * 100
                    resumen_entidad_top = resumen_entidad.sort_values(by='Porcentaje_Incumplimiento', ascending=False).head(10)
                    
                    if not resumen_entidad_top.empty:
                        fig2, ax2 = plt.subplots(figsize=(10, 6))
                        sns.barplot(
                            x='Porcentaje_Incumplimiento',
                            y=COLUMNA_ENTIDAD,
                            data=resumen_entidad_top,
                            palette='Reds_d',
                            ax=ax2
                        )
                        ax2.set_title('Top 10 Entidades con Mayor % de Incumplimiento (Min. 5 activos)', fontsize=14)
                        ax2.set_xlabel('Porcentaje de Activos en INCUMPLIMIENTO (%)', fontsize=12)
                        ax2.set_ylabel('Entidad Responsable', fontsize=12)
                        ax2.grid(axis='x', linestyle='--', alpha=0.6)
                        st.pyplot(fig2)
                        
                        st.markdown("### Resumen de Entidades (Top Global)")
                        st.dataframe(resumen_entidad_top, use_container_width=True)
                    else:
                        st.info("No hay entidades con suficiente volumen (>= 5 activos) o incumplimiento para mostrar el top 10.")
                else:
                    st.info("No hay entidades que cumplan el volumen m√≠nimo de 5 activos para el ranking.")
            except Exception as e:
                st.error(f"‚ùå ERROR [Visualizaci√≥n 2]: Fall√≥ la generaci√≥n del Bar Plot de Entidades. Detalle: {e}")
            
            st.markdown("---")

            # --- Visualizaci√≥n 3: Top 10 Categor√≠as ---
            st.subheader("3. Top 10 Categor√≠as con Mayor Cobertura Tem√°tica (Vista Actual)")
            
            try:
                COLUMNA_CATEGORIA = 'categoria'
                conteo_categoria = df_filtrado[COLUMNA_CATEGORIA].value_counts().head(10)
                
                if not conteo_categoria.empty:
                    fig3, ax3 = plt.subplots(figsize=(10, 7))
                    sns.barplot(x=conteo_categoria.values, y=conteo_categoria.index, palette='viridis', ax=ax3)

                    ax3.set_title('Top 10 Categor√≠as con Mayor Cobertura Tem√°tica (Vista Actual)', fontsize=16)
                    ax3.set_xlabel('N√∫mero de Activos', fontsize=12)
                    ax3.set_ylabel('Categor√≠a', fontsize=12)
                    st.pyplot(fig3)
                    
                    st.markdown("### Conteo de Categor√≠as (Vista Actual)")
                    st.dataframe(conteo_categoria.to_frame(), use_container_width=True)
                else:
                    st.info("La columna 'categoria' no contiene valores para generar la visualizaci√≥n con los filtros seleccionados.")
            except Exception as e:
                st.error(f"‚ùå ERROR [Visualizaci√≥n 3]: Fall√≥ la generaci√≥n del Bar Plot de Categor√≠as. Detalle: {e}")

except FileNotFoundError:
    st.error(f"‚ùå ERROR FATAL: No se encontr√≥ el archivo **{ARCHIVO_CSV}**.")
    st.info("Aseg√∫rate de que el archivo CSV est√© en la misma carpeta que `app.py`.")
except Exception as e:
    st.error(f"‚ùå ERROR FATAL: Ocurri√≥ un error inesperado durante la carga del archivo: {e}")
    st.info("Verifica que todas las librer√≠as est√©n instaladas y que el archivo CSV no est√© corrupto.")
