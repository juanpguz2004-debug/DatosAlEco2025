import streamlit as st
import pandas as pd
import joblib
import os
import altair as alt

# Para GPT4All
try:
    from gpt4all import GPT4All
except ImportError:
    st.error("La librer√≠a 'gpt4all' no est√° instalada. Ejecuta 'pip install gpt4all'.")
    GPT4All = None 

# ==========================================
# 1Ô∏è‚É£ Cargar datos
# ==========================================
@st.cache_data
def load_data():
    csv_file = "10.000_Empresas_mas_Grandes_del_Pa√≠s_20251115.csv"
    if not os.path.exists(csv_file):
        st.error(f"No se encontr√≥ el archivo CSV: **{csv_file}**. Aseg√∫rate de que est√© en el mismo directorio.")
        return pd.DataFrame()
    
    try:
        df = pd.read_csv(csv_file)
    except Exception as e:
        st.error(f"Error al leer el archivo CSV: {e}")
        return pd.DataFrame()

    # üõë FIX: Limpiar y estandarizar nombres de columnas para evitar KeyErrors üõë
    new_columns = {}
    for col in df.columns:
        # 1. Eliminar espacios iniciales/finales
        cleaned_col = col.strip()
        # 2. Reemplazar espacios internos por guiones bajos para consistencia con el c√≥digo
        cleaned_col = cleaned_col.replace(' ', '_')
        new_columns[col] = cleaned_col
    
    df = df.rename(columns=new_columns)
    
    # Verificar si las columnas cr√≠ticas existen despu√©s de la limpieza
    required_cols = ['MACROSECTOR', 'REGI√ìN', 'INGRESOS_OPERACIONALES']
    missing_cols = [col for col in required_cols if col not in df.columns]

    if missing_cols:
        st.error(f"Error Cr√≠tico: Las siguientes columnas clave son necesarias y no se encontraron en el CSV despu√©s de la limpieza: {missing_cols}")
        st.markdown(f"**Columnas encontradas en el archivo CSV:** `{list(df.columns)}`")
        return pd.DataFrame() 

    return df

df = load_data()

if df.empty:
    st.stop()  # Si no hay datos o la columna clave falta, detener la app

# ==========================================
# 2Ô∏è‚É£ Cargar modelo
# ==========================================
@st.cache_resource
def load_model():
    model_file = "model.pkl"
    if not os.path.exists(model_file):
        st.error(f"No se encontr√≥ el archivo del modelo: **{model_file}**. Aseg√∫rate de que est√© en el mismo directorio.")
        return None
    try:
        model = joblib.load(model_file)
        return model
    except Exception as e:
        st.error(f"Error al cargar el modelo PKL: {e}")
        return None

model = load_model()
if model is None:
    st.stop()

# ==========================================
# 3Ô∏è‚É£ Configurar GPT4All
# ==========================================
@st.cache_resource
def init_gpt():
    if GPT4All is None:
        return None
    # Cambia "ggml-model.bin" por el modelo que descargaste
    model_path = "ggml-model.bin"
    try:
        gpt_model = GPT4All(model_path)
        return gpt_model
    except Exception as e:
        st.warning(f"Error al inicializar GPT4All. La funcionalidad de consulta en lenguaje natural no estar√° disponible. Aseg√∫rate de que el modelo **{model_path}** est√© disponible. Error: {e}")
        return None

gpt = init_gpt()

# ==========================================
# 4Ô∏è‚É£ Interfaz Streamlit
# ==========================================
st.title("Dashboard de Empresas")
st.markdown("Explora los datos de las 10.000 empresas m√°s grandes del pa√≠s y genera predicciones de ganancias usando XGBoost.")

# Filtros interactivos
sector = st.selectbox("Selecciona un sector (MACROSECTOR)", ["Todos"] + df["MACROSECTOR"].dropna().unique().tolist())
region = st.selectbox("Selecciona una regi√≥n (REGI√ìN)", ["Todos"] + df["REGI√ìN"].dropna().unique().tolist())

# Filtrar datos
df_filtered = df.copy()
if sector != "Todos":
    df_filtered = df_filtered[df_filtered["MACROSECTOR"] == sector]
if region != "Todos":
    df_filtered = df_filtered[df_filtered["REGI√ìN"] == region]

st.dataframe(df_filtered.head(50))

if df_filtered.empty:
    st.error("No hay empresas que coincidan con los filtros seleccionados.")
    st.stop()

# ==========================================
# 5Ô∏è‚É£ Visualizaciones
# ==========================================
st.subheader("Visualizaciones")

# Agrupar por MACROSECTOR y sumar ingresos (Ahora la columna INGRESOS_OPERACIONALES debe existir)
df_chart = df_filtered.groupby('MACROSECTOR')['INGRESOS_OPERACIONALES'].sum().reset_index()

# Ejemplo: Ingresos por macrosector
chart = alt.Chart(df_chart).mark_bar().encode(
    x=alt.X('MACROSECTOR', title='Macrosector'),
    y=alt.Y('INGRESOS_OPERACIONALES', title='Ingresos Operacionales (Suma)'),
    tooltip=['MACROSECTOR', alt.Tooltip('INGRESOS_OPERACIONALES', format=',.0f', title='Total Ingresos')]
).properties(
    title='Suma de Ingresos Operacionales por Macrosector'
)
st.altair_chart(chart, use_container_width=True)

# ==========================================
# 6Ô∏è‚É£ Predicciones
# ==========================================
st.subheader("Predicciones de Ganancias")
max_index = len(df_filtered) - 1
empresa_idx = st.number_input(
    f"Selecciona √≠ndice de empresa para predecir ganancia (0 a {max_index})", 
    min_value=0, 
    max_value=max_index, 
    value=0
)

# Columnas que se deben eliminar del DataFrame para obtener solo las features del modelo
X_pred = df_filtered.drop(columns=["GANANCIA_(P√âRDIDA)", "RAZ√ìN_SOCIAL", "NIT", "SUPERVISOR", "REGI√ìN", "DEPARTAMENTO DOMICILIO", "CIUDAD DOMICILIO", "CIIU", "MACROSECTOR", "A√±o de Corte"], errors='ignore')

# Realizar la predicci√≥n
try:
    pred_value = model.predict(X_pred.iloc[[empresa_idx]])[0]
    st.write(f"Predicci√≥n de ganancia para la empresa **{df_filtered.iloc[empresa_idx]['RAZ√ìN_SOCIAL']}**: **${pred_value:,.2f}**")
except Exception as e:
    st.error(f"Error al realizar la predicci√≥n. Aseg√∫rate de que las columnas de features de la empresa coincidan con las que espera el modelo. Error: {e}")

# ==========================================
# 7Ô∏è‚É£ Preguntas con GPT4All
# ==========================================
st.subheader("Consulta en lenguaje natural")
user_question = st.text_input("Hazle una pregunta a GPT4All sobre los datos o las predicciones:")

if user_question:
    if gpt:
        # Pasamos un resumen de los datos al prompt para contexto
        context = f"Datos de empresas (top 5):\n{df_filtered.head(5).to_string()}"
        prompt = f"{context}\nPregunta: {user_question}\nRespuesta:"
        
        try:
            response = gpt.chat(prompt)
            st.markdown(f"**GPT4All:** {response}")
        except Exception as e:
            st.error(f"Error al generar respuesta con GPT4All: {e}")
    else:
        st.warning("GPT4All no se pudo inicializar. Consulta en lenguaje natural no disponible.")
